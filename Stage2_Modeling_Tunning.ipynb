{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "144335bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import sklearn\n",
    "import xgboost\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21fedd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.13.2 | packaged by Anaconda, Inc. | (main, Feb  6 2025, 18:49:14) [MSC v.1929 64 bit (AMD64)]\n",
      "pandas: 2.2.3\n",
      "numpy: 2.2.5\n",
      "scikit-learn: 1.6.1\n",
      "xgboost: 3.0.1\n",
      "joblib: 1.5.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Python:\", os.sys.version)\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"scikit-learn:\", sklearn.__version__)\n",
    "print(\"xgboost:\", xgboost.__version__)\n",
    "print(\"joblib:\", joblib.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725cce0d",
   "metadata": {},
   "source": [
    "## Environment dan Versi Library\n",
    "\n",
    "Notebook ini dijalankan menggunakan **Python 3.13.2 (Anaconda)** dengan versi library sebagai berikut:\n",
    "\n",
    "| Library       | Version  |\n",
    "|---------------|----------|\n",
    "| pandas        | 2.2.3    |\n",
    "| numpy         | 2.2.5    |\n",
    "| scikit-learn  | 1.6.1    |\n",
    "| xgboost       | 3.0.1    |\n",
    "| joblib        | 1.5.1    |\n",
    "\n",
    "Untuk mereplikasi environment ini, jalankan:\n",
    "```bash\n",
    "pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9da4c0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Age                  1500 non-null   int64  \n",
      " 1   Gender               1500 non-null   int64  \n",
      " 2   EducationLevel       1500 non-null   int64  \n",
      " 3   ExperienceYears      1500 non-null   int64  \n",
      " 4   PreviousCompanies    1500 non-null   int64  \n",
      " 5   DistanceFromCompany  1500 non-null   float64\n",
      " 6   InterviewScore       1500 non-null   int64  \n",
      " 7   SkillScore           1500 non-null   int64  \n",
      " 8   PersonalityScore     1500 non-null   int64  \n",
      " 9   RecruitmentStrategy  1500 non-null   int64  \n",
      " 10  HiringDecision       1500 non-null   int64  \n",
      "dtypes: float64(1), int64(10)\n",
      "memory usage: 129.0 KB\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('dataset/recruitment_data.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d91a0d",
   "metadata": {},
   "source": [
    "## Convert data int to category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "91e849a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_convert = [\"Gender\", \"EducationLevel\", \"RecruitmentStrategy\"]\n",
    "\n",
    "# ubah tipe data ke category\n",
    "df[cols_to_convert] = df[cols_to_convert].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b42eeb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype   \n",
      "---  ------               --------------  -----   \n",
      " 0   Age                  1500 non-null   int64   \n",
      " 1   Gender               1500 non-null   category\n",
      " 2   EducationLevel       1500 non-null   category\n",
      " 3   ExperienceYears      1500 non-null   int64   \n",
      " 4   PreviousCompanies    1500 non-null   int64   \n",
      " 5   DistanceFromCompany  1500 non-null   float64 \n",
      " 6   InterviewScore       1500 non-null   int64   \n",
      " 7   SkillScore           1500 non-null   int64   \n",
      " 8   PersonalityScore     1500 non-null   int64   \n",
      " 9   RecruitmentStrategy  1500 non-null   category\n",
      " 10  HiringDecision       1500 non-null   int64   \n",
      "dtypes: category(3), float64(1), int64(7)\n",
      "memory usage: 98.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea9386c",
   "metadata": {},
   "source": [
    "##  Split Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a26249dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukuran X_train: (1200, 10)\n",
      "Ukuran X_test : (300, 10)\n",
      "Ukuran y_train: (1200,)\n",
      "Ukuran y_test : (300,)\n",
      "Dataset berhasil disimpan ke 'train.csv' dan 'test.csv'\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(\"HiringDecision\", axis=1)  \n",
    "y = df[\"HiringDecision\"]\n",
    "\n",
    "# split data: 80% train, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Ukuran X_train:\", X_train.shape)\n",
    "print(\"Ukuran X_test :\", X_test.shape)\n",
    "print(\"Ukuran y_train:\", y_train.shape)\n",
    "print(\"Ukuran y_test :\", y_test.shape)\n",
    "\n",
    "# gabungkan kembali X dan y agar sesuai dengan data awal\n",
    "train_set = pd.concat([X_train, y_train], axis=1)\n",
    "test_set = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "# simpan ke CSV\n",
    "train_set.to_csv(\"dataset/train.csv\", index=False)\n",
    "test_set.to_csv(\"dataset/test.csv\", index=False)\n",
    "\n",
    "print(\"Dataset berhasil disimpan ke 'train.csv' dan 'test.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81ed885",
   "metadata": {},
   "source": [
    "## Pipeline Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "948e95e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# 1. Load data from CSV\n",
    "# =====================\n",
    "train_df = pd.read_csv(\"dataset/train.csv\")\n",
    "test_df = pd.read_csv(\"dataset/test.csv\")\n",
    "\n",
    "X_train = train_df.drop([\"HiringDecision\", \"Age\", \"DistanceFromCompany\", \"Gender\",'PreviousCompanies'], axis=1)\n",
    "y_train = train_df[\"HiringDecision\"]\n",
    "\n",
    "X_test = test_df.drop([\"HiringDecision\", \"Age\", \"DistanceFromCompany\", \"Gender\",'PreviousCompanies'], axis=1)\n",
    "y_test = test_df[\"HiringDecision\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "38391930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline preprocessing berhasil disimpan.\n",
      "Train shape: (1200, 10)\n",
      "Test shape : (300, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =====================\n",
    "# 3. Preprocessing setup\n",
    "# =====================\n",
    "\n",
    "class DataCleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        \n",
    "        # 1. Drop duplicates\n",
    "        X = X.drop_duplicates()\n",
    "        \n",
    "        # 2. Missing value handling\n",
    "        for col in X.select_dtypes(include=[\"float\", \"int\"]).columns:\n",
    "            X[col] = X[col].fillna(X[col].median())   # numeric → median\n",
    "        for col in X.select_dtypes(include=[\"object\"]).columns:\n",
    "            X[col] = X[col].fillna(X[col].mode()[0]) # categorical → modus\n",
    "        \n",
    "        # 3. Outlier handling (IQR method pada numerical)\n",
    "        for col in X.select_dtypes(include=[\"float\", \"int\"]).columns:\n",
    "            Q1 = X[col].quantile(0.25)\n",
    "            Q3 = X[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower, upper = Q1 - 1.5*IQR, Q3 + 1.5*IQR\n",
    "            X[col] = np.where(X[col] < lower, lower,\n",
    "                              np.where(X[col] > upper, upper, X[col]))\n",
    "        \n",
    "        return X\n",
    "    \n",
    "# b. ExperienceYears → binning (junior/mid/senior)\n",
    "def bin_experience(x):\n",
    "    bins = np.array(x).astype(int).ravel()\n",
    "    labels = []\n",
    "    for v in bins:\n",
    "        if v <=2:\n",
    "            labels.append(\"Junior\")\n",
    "        elif v <=5:\n",
    "            labels.append(\"Mid\")\n",
    "        else:\n",
    "            labels.append(\"Senior\")\n",
    "    return np.array(labels).reshape(-1,1)\n",
    "\n",
    "# a. EducationLevel → OH encode\n",
    "edu_pipeline = Pipeline([\n",
    "    (\"onehot\", OneHotEncoder(drop=\"first\"))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "exp_pipeline = Pipeline([\n",
    "    (\"binning\", FunctionTransformer(bin_experience, validate=False)),\n",
    "    (\"onehot\", OneHotEncoder(drop=\"first\"))  # one-hot encode hasil binning\n",
    "])\n",
    "\n",
    "# c. RecruitmentStrategy → one-hot encode\n",
    "recruitment_pipeline = Pipeline([\n",
    "    (\"onehot\", OneHotEncoder(drop=\"first\"))\n",
    "])\n",
    "\n",
    "# d. Numerical features → scaling\n",
    "num_features = [\"InterviewScore\", \"SkillScore\", \"PersonalityScore\"]\n",
    "num_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# =====================\n",
    "# 4. ColumnTransformer\n",
    "# =====================\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"education\", edu_pipeline, [\"EducationLevel\"]),\n",
    "        (\"experience\", exp_pipeline, [\"ExperienceYears\"]),\n",
    "        (\"recruitment\", recruitment_pipeline, [\"RecruitmentStrategy\"]),\n",
    "        (\"num\", num_pipeline, num_features)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "\n",
    "# Pipeline gabungan: cleaning + preprocessing\n",
    "full_pipeline = Pipeline([\n",
    "    (\"cleaning\", DataCleaner()),   # tahap cleaning\n",
    "    (\"preprocessing\", preprocessor) # tahap preprocessing (OH, scaling, dsb.)\n",
    "])\n",
    "\n",
    "# preprocessor.fit(X_train)\n",
    "# Simpan pipeline preprocessing\n",
    "joblib.dump(preprocessor, \"preprocesor.pkl\")\n",
    "print(\"Pipeline preprocessing berhasil disimpan.\")\n",
    "\n",
    "# Transform data\n",
    "X_train_transformed = full_pipeline.fit_transform(X_train)\n",
    "X_test_transformed  = full_pipeline.transform(X_test)\n",
    "\n",
    "print(\"Train shape:\", X_train_transformed.shape)\n",
    "print(\"Test shape :\", X_test_transformed.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7e91a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd43b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d118981b",
   "metadata": {},
   "source": [
    "## Check data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2dd3d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 1. Education (one-hot)\n",
    "edu_encoder = preprocessor.named_transformers_[\"education\"].named_steps[\"onehot\"]\n",
    "edu_cols = edu_encoder.get_feature_names_out([\"EducationLevel\"]).tolist()\n",
    "\n",
    "# 2. ExperienceYears (binning + onehot drop=\"first\" → 2 kolom)\n",
    "exp_cols = [\"ExperienceLevel_Mid\", \"ExperienceLevel_Senior\"]\n",
    "\n",
    "# 3. RecruitmentStrategy (ambil langsung dari OneHotEncoder)\n",
    "recruitment_encoder = preprocessor.named_transformers_[\"recruitment\"].named_steps[\"onehot\"]\n",
    "recruitment_cols = recruitment_encoder.get_feature_names_out([\"RecruitmentStrategy\"]).tolist()\n",
    "\n",
    "# 5. Numeric features\n",
    "num_cols = num_features\n",
    "\n",
    "# Gabung semua nama kolom\n",
    "all_cols =  edu_cols + exp_cols + recruitment_cols + num_cols\n",
    "\n",
    "# Buat DataFrame hasil transform\n",
    "X_train_df = pd.DataFrame(X_train_transformed, columns=all_cols, index=X_train.index)\n",
    "X_test_df  = pd.DataFrame(X_test_transformed, columns=all_cols, index=X_test.index)\n",
    "\n",
    "X_train_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6f3251bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EducationLevel_2.0</th>\n",
       "      <th>EducationLevel_3.0</th>\n",
       "      <th>EducationLevel_4.0</th>\n",
       "      <th>ExperienceLevel_Mid</th>\n",
       "      <th>ExperienceLevel_Senior</th>\n",
       "      <th>RecruitmentStrategy_2.0</th>\n",
       "      <th>RecruitmentStrategy_3.0</th>\n",
       "      <th>InterviewScore</th>\n",
       "      <th>SkillScore</th>\n",
       "      <th>PersonalityScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.183148</td>\n",
       "      <td>1.242828</td>\n",
       "      <td>0.924557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.635513</td>\n",
       "      <td>0.800611</td>\n",
       "      <td>1.637344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.201568</td>\n",
       "      <td>-1.206373</td>\n",
       "      <td>-0.195535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.567865</td>\n",
       "      <td>-0.560056</td>\n",
       "      <td>1.603402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.092479</td>\n",
       "      <td>-0.900223</td>\n",
       "      <td>-1.553224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EducationLevel_2.0  EducationLevel_3.0  EducationLevel_4.0  \\\n",
       "0                 0.0                 1.0                 0.0   \n",
       "1                 0.0                 1.0                 0.0   \n",
       "2                 0.0                 0.0                 0.0   \n",
       "3                 1.0                 0.0                 0.0   \n",
       "4                 1.0                 0.0                 0.0   \n",
       "\n",
       "   ExperienceLevel_Mid  ExperienceLevel_Senior  RecruitmentStrategy_2.0  \\\n",
       "0                  0.0                     1.0                      0.0   \n",
       "1                  0.0                     0.0                      1.0   \n",
       "2                  0.0                     1.0                      1.0   \n",
       "3                  0.0                     0.0                      0.0   \n",
       "4                  1.0                     0.0                      0.0   \n",
       "\n",
       "   RecruitmentStrategy_3.0  InterviewScore  SkillScore  PersonalityScore  \n",
       "0                      0.0       -0.183148    1.242828          0.924557  \n",
       "1                      0.0        1.635513    0.800611          1.637344  \n",
       "2                      0.0        0.201568   -1.206373         -0.195535  \n",
       "3                      1.0       -0.567865   -0.560056          1.603402  \n",
       "4                      0.0       -1.092479   -0.900223         -1.553224  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1200, 10)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(X_train_df.head())\n",
    "X_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daccdc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d60bfaba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EducationLevel_2.0</th>\n",
       "      <th>EducationLevel_3.0</th>\n",
       "      <th>EducationLevel_4.0</th>\n",
       "      <th>ExperienceLevel_Mid</th>\n",
       "      <th>ExperienceLevel_Senior</th>\n",
       "      <th>RecruitmentStrategy_2.0</th>\n",
       "      <th>RecruitmentStrategy_3.0</th>\n",
       "      <th>InterviewScore</th>\n",
       "      <th>SkillScore</th>\n",
       "      <th>PersonalityScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.530590</td>\n",
       "      <td>0.630528</td>\n",
       "      <td>-0.942264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.306491</td>\n",
       "      <td>-0.900223</td>\n",
       "      <td>-1.553224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.565564</td>\n",
       "      <td>0.664544</td>\n",
       "      <td>1.569459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.442222</td>\n",
       "      <td>1.480945</td>\n",
       "      <td>-0.195535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.936028</td>\n",
       "      <td>-1.512523</td>\n",
       "      <td>-0.602842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EducationLevel_2.0  EducationLevel_3.0  EducationLevel_4.0  \\\n",
       "0                 1.0                 0.0                 0.0   \n",
       "1                 0.0                 0.0                 1.0   \n",
       "2                 0.0                 1.0                 0.0   \n",
       "3                 1.0                 0.0                 0.0   \n",
       "4                 0.0                 0.0                 0.0   \n",
       "\n",
       "   ExperienceLevel_Mid  ExperienceLevel_Senior  RecruitmentStrategy_2.0  \\\n",
       "0                  0.0                     1.0                      1.0   \n",
       "1                  0.0                     1.0                      0.0   \n",
       "2                  0.0                     0.0                      1.0   \n",
       "3                  0.0                     0.0                      1.0   \n",
       "4                  0.0                     1.0                      1.0   \n",
       "\n",
       "   RecruitmentStrategy_3.0  InterviewScore  SkillScore  PersonalityScore  \n",
       "0                      0.0        1.530590    0.630528         -0.942264  \n",
       "1                      1.0        0.306491   -0.900223         -1.553224  \n",
       "2                      0.0        1.565564    0.664544          1.569459  \n",
       "3                      0.0       -1.442222    1.480945         -0.195535  \n",
       "4                      0.0        0.936028   -1.512523         -0.602842  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(300, 10)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(X_test_df.head())\n",
    "X_test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a1937f",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "15ba5d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_rank_models(models, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Melatih, mengevaluasi, dan mengurutkan model berdasarkan performa pada data uji.\n",
    "    \n",
    "    Args:\n",
    "        models (dict): Kamus berisi model-model yang sudah diinisialisasi.\n",
    "        X_train, y_train: Data latih.\n",
    "        X_test, y_test: Data uji.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame yang berisi hasil evaluasi model yang diurutkan\n",
    "                      berdasarkan metrik ROC-AUC.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Melatih semua model\n",
    "    for name, model in models.items():\n",
    "        # print(f\"Melatih model: {name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "    # 2. Mengevaluasi model dan mengumpulkan hasilnya\n",
    "    results = []\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_prob = model.predict_proba(X_test)[:, 1]\n",
    "        else:\n",
    "            y_prob = model.decision_function(X_test)\n",
    "        \n",
    "        acc  = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred)\n",
    "        rec  = recall_score(y_test, y_pred)\n",
    "        f1   = f1_score(y_test, y_pred)\n",
    "        auc  = roc_auc_score(y_test, y_prob)\n",
    "        \n",
    "        results.append({\n",
    "            \"Model\": name,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": prec,\n",
    "            \"Recall\": rec,\n",
    "            \"F1-Score\": f1,\n",
    "            \"ROC-AUC\": auc\n",
    "        })\n",
    "        \n",
    "    # 3. Membuat DataFrame dan mengurutkan\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values(by=\"ROC-AUC\", ascending=False)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Contoh penggunaan fungsi\n",
    "# Asumsi 'models', X_train, y_train, X_test, y_test sudah didefinisikan\n",
    "\n",
    "# hasil_evaluasi = evaluate_and_rank_models(models, X_train, y_train, X_test, y_test)\n",
    "# print(\"Hasil Evaluasi Model:\")\n",
    "# display(hasil_evaluasi)\n",
    "\n",
    "# Visualisasi (jika diperlukan)\n",
    "# plt.figure(figsize=(8,5))\n",
    "# plt.barh(hasil_evaluasi[\"Model\"], hasil_evaluasi[\"ROC-AUC\"], color=\"teal\")\n",
    "# plt.xlabel(\"ROC-AUC\")\n",
    "# plt.title(\"Perbandingan ROC-AUC antar Model\")\n",
    "# plt.gca().invert_yaxis()\n",
    "# plt.show()\n",
    "\n",
    "def calculate_overfitting_gap(models, X_train, y_train, X_test, y_test, sort_by='F1-Score Gap (%)'):\n",
    "    \"\"\"\n",
    "    Menghitung dan menampilkan gap overfitting (persentase perbedaan)\n",
    "    untuk beberapa model, diurutkan berdasarkan gap terkecil.\n",
    "\n",
    "    Args:\n",
    "        models (dict): Kamus berisi model-model yang sudah dilatih.\n",
    "        X_train, y_train: Fitur dan target untuk data latih.\n",
    "        X_test, y_test: Fitur dan target untuk data uji.\n",
    "        sort_by (str): Nama kolom metrik untuk mengurutkan hasil.\n",
    "                       Default adalah 'F1-Score Gap (%)'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame yang menampilkan persentase gap untuk setiap metrik,\n",
    "                      diurutkan dari gap terkecil ke terbesar.\n",
    "    \"\"\"\n",
    "    gap_data = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        # Hitung metrik untuk data latih\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_train_prob = model.predict_proba(X_train)[:, 1] if hasattr(model, \"predict_proba\") else model.decision_function(X_train)\n",
    "        \n",
    "        metrics_train = {\n",
    "            'Accuracy': accuracy_score(y_train, y_train_pred),\n",
    "            'Precision': precision_score(y_train, y_train_pred),\n",
    "            'Recall': recall_score(y_train, y_train_pred),\n",
    "            'F1-Score': f1_score(y_train, y_train_pred),\n",
    "            'ROC-AUC': roc_auc_score(y_train, y_train_prob)\n",
    "        }\n",
    "\n",
    "        # Hitung metrik untuk data uji\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        y_test_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else model.decision_function(X_test)\n",
    "\n",
    "        metrics_test = {\n",
    "            'Accuracy': accuracy_score(y_test, y_test_pred),\n",
    "            'Precision': precision_score(y_test, y_test_pred),\n",
    "            'Recall': recall_score(y_test, y_test_pred),\n",
    "            'F1-Score': f1_score(y_test, y_test_pred),\n",
    "            'ROC-AUC': roc_auc_score(y_test, y_test_prob)\n",
    "        }\n",
    "        \n",
    "        # Hitung persentase gap untuk setiap metrik\n",
    "        gaps = {\n",
    "            \"Model\": name,\n",
    "            \"Accuracy Gap (%)\": (metrics_train['Accuracy'] - metrics_test['Accuracy']) / metrics_train['Accuracy'] * 100,\n",
    "            \"Precision Gap (%)\": (metrics_train['Precision'] - metrics_test['Precision']) / metrics_train['Precision'] * 100,\n",
    "            \"Recall Gap (%)\": (metrics_train['Recall'] - metrics_test['Recall']) / metrics_train['Recall'] * 100,\n",
    "            \"F1-Score Gap (%)\": (metrics_train['F1-Score'] - metrics_test['F1-Score']) / metrics_train['F1-Score'] * 100,\n",
    "            \"ROC-AUC Gap (%)\": (metrics_train['ROC-AUC'] - metrics_test['ROC-AUC']) / metrics_train['ROC-AUC'] * 100\n",
    "        }\n",
    "        \n",
    "        gap_data.append(gaps)\n",
    "\n",
    "    df_gaps = pd.DataFrame(gap_data).set_index(\"Model\")\n",
    "    return df_gaps.sort_values(by=sort_by, ascending=True)\n",
    "\n",
    "def evaluate_and_display(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Mengevaluasi model pada data train dan test,\n",
    "    lalu menampilkan hasilnya dalam bentuk DataFrame,\n",
    "    termasuk gap (%) antara train dan test.\n",
    "    \"\"\"\n",
    "    # === TRAIN ===\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_train_prob = model.predict_proba(X_train)[:, 1]\n",
    "    report_train = classification_report(y_train, y_train_pred, output_dict=True)\n",
    "    roc_auc_train = roc_auc_score(y_train, y_train_prob)\n",
    "\n",
    "    # === TEST ===\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_prob = model.predict_proba(X_test)[:, 1]\n",
    "    report_test = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "    roc_auc_test = roc_auc_score(y_test, y_test_prob)\n",
    "\n",
    "    # === Gabungkan semua metrik ===\n",
    "    metrics = {\n",
    "        \"Precision (class 1)\": [round(report_train[\"1\"][\"precision\"], 3), round(report_test[\"1\"][\"precision\"], 3)],\n",
    "        \"Recall (class 1)\":    [round(report_train[\"1\"][\"recall\"], 3),    round(report_test[\"1\"][\"recall\"], 3)],\n",
    "        \"F1-score (class 1)\":  [round(report_train[\"1\"][\"f1-score\"], 3),  round(report_test[\"1\"][\"f1-score\"], 3)],\n",
    "        \"Accuracy\":            [round(report_train[\"accuracy\"], 3),       round(report_test[\"accuracy\"], 3)],\n",
    "        \"ROC AUC\":             [round(roc_auc_train, 3),                  round(roc_auc_test, 3)]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics, index=[\"Train\", \"Test\"])\n",
    "\n",
    "    # === Hitung Gap (%) ===\n",
    "    # (Train - Test) / Train * 100\n",
    "    gap_values = ((df_metrics.loc[\"Train\"] - df_metrics.loc[\"Test\"]) \n",
    "                  / df_metrics.loc[\"Train\"] * 100).round(2)\n",
    "\n",
    "    df_metrics.loc[\"Gap (%)\"] = gap_values\n",
    "\n",
    "    return df_metrics\n",
    "\n",
    "\n",
    "# Contoh Penggunaan:\n",
    "# Anda bisa memanggil fungsi ini setelah melatih model Anda\n",
    "# df_evaluasi = evaluate_and_display(model, X_train_transformed, y_train, X_test_transformed, y_test)\n",
    "# print(df_evaluasi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e30603",
   "metadata": {},
   "source": [
    "### Base Model LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce500fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91       207\n",
      "           1       0.76      0.87      0.81        93\n",
      "\n",
      "    accuracy                           0.88       300\n",
      "   macro avg       0.85      0.88      0.86       300\n",
      "weighted avg       0.88      0.88      0.88       300\n",
      "\n",
      "ROC AUC: 0.9219780790608281\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = LogisticRegression(max_iter=1000, random_state=42,class_weight=\"balanced\")\n",
    "model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# =====================\n",
    "# 7. Evaluation\n",
    "# =====================\n",
    "y_pred = model.predict(X_test_transformed)\n",
    "y_prob = model.predict_proba(X_test_transformed)[:, 1]\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob))\n",
    "\n",
    "# # =====================\n",
    "# # 8. Save Model + Preprocessor\n",
    "# # =====================\n",
    "# import joblib\n",
    "# joblib.dump(preprocessor, \"preprocessor.pkl\")\n",
    "# joblib.dump(model, \"logreg_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ddae4b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Evaluasi Model (dengan Gap):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision (class 1)</th>\n",
       "      <th>Recall (class 1)</th>\n",
       "      <th>F1-score (class 1)</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.756</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.764</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gap (%)</th>\n",
       "      <td>-1.060</td>\n",
       "      <td>2.350</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Precision (class 1)  Recall (class 1)  F1-score (class 1)  Accuracy  \\\n",
       "Train                  0.756             0.892               0.819     0.877   \n",
       "Test                   0.764             0.871               0.814     0.877   \n",
       "Gap (%)               -1.060             2.350               0.610     0.000   \n",
       "\n",
       "         ROC AUC  \n",
       "Train      0.927  \n",
       "Test       0.922  \n",
       "Gap (%)    0.540  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_eval_baseline = evaluate_and_display(model, X_train_transformed, y_train, X_test_transformed, y_test)\n",
    "print(\"Hasil Evaluasi Model (dengan Gap):\")\n",
    "display(result_eval_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "699dca03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Nama folder yang diinginkan\n",
    "# folder_path = 'file_exp'\n",
    "\n",
    "# # Cek apakah folder sudah ada, jika tidak, buat folder tersebut\n",
    "# if not os.path.exists(folder_path):\n",
    "#     os.path.makedirs(folder_path)\n",
    "#     print(f\"Folder '{folder_path}' berhasil dibuat.\")\n",
    "\n",
    "# # Buat path lengkap untuk file Excel\n",
    "# file_path = os.path.join(folder_path, 'result_eval_baseline.xlsx')\n",
    "\n",
    "# # Asumsikan 'hasil_evaluasi' adalah DataFrame\n",
    "# result_eval_baseline.to_excel(file_path, index=True)\n",
    "\n",
    "# print(f\"Hasil evaluasi telah berhasil disimpan ke: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad10ace0",
   "metadata": {},
   "source": [
    "## Test to many models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6fcb2487",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42,class_weight=\"balanced\"),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"SVM\": SVC(probability=True, random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2dfad4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Evaluasi Model:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.943483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.923333</td>\n",
       "      <td>0.960526</td>\n",
       "      <td>0.784946</td>\n",
       "      <td>0.863905</td>\n",
       "      <td>0.932757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.903333</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.763441</td>\n",
       "      <td>0.830409</td>\n",
       "      <td>0.928367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.913333</td>\n",
       "      <td>0.958904</td>\n",
       "      <td>0.752688</td>\n",
       "      <td>0.843373</td>\n",
       "      <td>0.928315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.876667</td>\n",
       "      <td>0.764151</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.814070</td>\n",
       "      <td>0.921978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.915147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.796667</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.625767</td>\n",
       "      <td>0.841619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.863333</td>\n",
       "      <td>0.851351</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.754491</td>\n",
       "      <td>0.812140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1-Score   ROC-AUC\n",
       "3        Random Forest  0.920000   0.960000  0.774194  0.857143  0.943483\n",
       "4    Gradient Boosting  0.923333   0.960526  0.784946  0.863905  0.932757\n",
       "7              XGBoost  0.903333   0.910256  0.763441  0.830409  0.928367\n",
       "5                  SVM  0.913333   0.958904  0.752688  0.843373  0.928315\n",
       "0  Logistic Regression  0.876667   0.764151  0.870968  0.814070  0.921978\n",
       "1                  KNN  0.860000   0.840000  0.677419  0.750000  0.915147\n",
       "6          Naive Bayes  0.796667   0.728571  0.548387  0.625767  0.841619\n",
       "2        Decision Tree  0.863333   0.851351  0.677419  0.754491  0.812140"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Evaluasi Model (dengan Gap):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy Gap (%)</th>\n",
       "      <th>Precision Gap (%)</th>\n",
       "      <th>Recall Gap (%)</th>\n",
       "      <th>F1-Score Gap (%)</th>\n",
       "      <th>ROC-AUC Gap (%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>4.317789</td>\n",
       "      <td>0.848896</td>\n",
       "      <td>14.369501</td>\n",
       "      <td>8.289229</td>\n",
       "      <td>3.532126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>7.923269</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>22.371968</td>\n",
       "      <td>14.170196</td>\n",
       "      <td>5.651654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>9.666667</td>\n",
       "      <td>8.974359</td>\n",
       "      <td>23.655914</td>\n",
       "      <td>16.959064</td>\n",
       "      <td>7.163264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Accuracy Gap (%)  Precision Gap (%)  Recall Gap (%)  \\\n",
       "Model                                                                    \n",
       "Gradient Boosting          4.317789           0.848896       14.369501   \n",
       "Random Forest              7.923269           4.000000       22.371968   \n",
       "XGBoost                    9.666667           8.974359       23.655914   \n",
       "\n",
       "                   F1-Score Gap (%)  ROC-AUC Gap (%)  \n",
       "Model                                                 \n",
       "Gradient Boosting          8.289229         3.532126  \n",
       "Random Forest             14.170196         5.651654  \n",
       "XGBoost                   16.959064         7.163264  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_eval_7model = evaluate_and_rank_models(models, X_train_transformed, y_train, X_test_transformed, y_test)\n",
    "print(\"Hasil Evaluasi Model:\")\n",
    "display(result_eval_7model)\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(8,5))\n",
    "# plt.barh(hasil_evaluasi[\"Model\"], hasil_evaluasi[\"ROC-AUC\"], color=\"teal\")\n",
    "# plt.xlabel(\"ROC-AUC\")\n",
    "# plt.title(\"Perbandingan ROC-AUC antar Model\")\n",
    "# plt.gca().invert_yaxis()\n",
    "# plt.show()\n",
    "models3 = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "result_eval_7model_gap = calculate_overfitting_gap(models3, X_train_transformed, y_train, X_test_transformed, y_test)\n",
    "print(\"Hasil Evaluasi Model (dengan Gap):\")\n",
    "display(result_eval_7model_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bb05685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Nama folder yang diinginkan\n",
    "# folder_path = 'file_exp'\n",
    "\n",
    "# # Cek apakah folder sudah ada, jika tidak, buat folder tersebut\n",
    "# if not os.path.exists(folder_path):\n",
    "#     os.path.makedirs(folder_path)\n",
    "#     print(f\"Folder '{folder_path}' berhasil dibuat.\")\n",
    "\n",
    "# # Buat path lengkap untuk file pertama\n",
    "# file_path_1 = os.path.join(folder_path, 'result_eval_7model.xlsx')\n",
    "# # Buat path lengkap untuk file kedua\n",
    "# file_path_2 = os.path.join(folder_path, 'result_eval_7model_gap.xlsx')\n",
    "\n",
    "# # Simpan DataFrame pertama ke file pertama\n",
    "# result_eval_7model.to_excel(file_path_1, index=True)\n",
    "\n",
    "# # Simpan DataFrame kedua ke file kedua\n",
    "# result_eval_7model_gap.to_excel(file_path_2, index=True)\n",
    "\n",
    "# print(f\"Hasil evaluasi pertama berhasil disimpan ke: {file_path_1}\")\n",
    "# print(f\"Hasil evaluasi kedua berhasil disimpan ke: {file_path_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc8ccc1",
   "metadata": {},
   "source": [
    "Jika ingin performa tertinggi (F1-Score + Recall balance) → Gradient Boosting.\n",
    "\n",
    "Jika ingin pemisahan kelas terbaik (ROC-AUC tertinggi) → Random Forest.h."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05488936",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning untuk random forest dan gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5310c8d9",
   "metadata": {},
   "source": [
    "## Random forest , Gradient Boosting & XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "42dda5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# Fungsi Evaluasi Model (Train vs Test)\n",
    "# =========================================\n",
    "def evaluate_train_test(model, X_train, y_train, X_test, y_test, model_name=\"Model\"):\n",
    "    # Prediksi Train\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_train_prob = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "    # Prediksi Test\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Hasil Train\n",
    "    train_results = {\n",
    "        \"Accuracy\": accuracy_score(y_train, y_train_pred),\n",
    "        \"Precision\": precision_score(y_train, y_train_pred),\n",
    "        \"Recall\": recall_score(y_train, y_train_pred),\n",
    "        \"F1-Score\": f1_score(y_train, y_train_pred),\n",
    "        \"ROC-AUC\": roc_auc_score(y_train, y_train_prob)\n",
    "    }\n",
    "\n",
    "    # Hasil Test\n",
    "    test_results = {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_test_pred),\n",
    "        \"Precision\": precision_score(y_test, y_test_pred),\n",
    "        \"Recall\": recall_score(y_test, y_test_pred),\n",
    "        \"F1-Score\": f1_score(y_test, y_test_pred),\n",
    "        \"ROC-AUC\": roc_auc_score(y_test, y_test_prob)\n",
    "    }\n",
    "\n",
    "    # Gap (%)\n",
    "    gap_results = {m: 100 * (train_results[m] - test_results[m]) for m in train_results}\n",
    "\n",
    "    # Buat DataFrame untuk tampilan tabel\n",
    "    df_results = pd.DataFrame([\n",
    "        {\"Model\": model_name, \"Dataset\": \"Train\", **train_results},\n",
    "        {\"Model\": model_name, \"Dataset\": \"Test\", **test_results},\n",
    "        {\"Model\": model_name, \"Dataset\": \"Gap (%)\", **gap_results},\n",
    "    ])\n",
    "\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f8fb1618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "========================================\n",
      "===== Hasil Hyperparameter Tuning (Random Forest) =====\n",
      "Best Hyperparameter: {'n_estimators': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': True}\n",
      "Best F1 Score : 0.8594049335803413\n",
      "\n",
      "Result Model evaluation Train vs Test:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.911290</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.998299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.935432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Gap (%)</td>\n",
       "      <td>4.500</td>\n",
       "      <td>1.413793</td>\n",
       "      <td>13.709677</td>\n",
       "      <td>8.452381</td>\n",
       "      <td>6.286686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Dataset  Accuracy  Precision     Recall  F1-Score   ROC-AUC\n",
       "0  Random Forest    Train     0.965   0.974138   0.911290  0.941667  0.998299\n",
       "1  Random Forest     Test     0.920   0.960000   0.774194  0.857143  0.935432\n",
       "2  Random Forest  Gap (%)     4.500   1.413793  13.709677  8.452381  6.286686"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "========================================\n",
      "===== Hasil Hyperparameter Tuning (Gradient Boosting) =====\n",
      "Best Hyperparameter: {'subsample': 1.0, 'n_estimators': np.int64(100), 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 2, 'learning_rate': np.float64(0.2677777777777778)}\n",
      "Best F1 Score : 0.8927087525169505\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.963068</td>\n",
       "      <td>0.911290</td>\n",
       "      <td>0.936464</td>\n",
       "      <td>0.958096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.936667</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.827957</td>\n",
       "      <td>0.890173</td>\n",
       "      <td>0.933328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Gap (%)</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.056818</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>4.629068</td>\n",
       "      <td>2.476819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Dataset  Accuracy  Precision    Recall  F1-Score  \\\n",
       "0  Gradient Boosting    Train  0.961667   0.963068  0.911290  0.936464   \n",
       "1  Gradient Boosting     Test  0.936667   0.962500  0.827957  0.890173   \n",
       "2  Gradient Boosting  Gap (%)  2.500000   0.056818  8.333333  4.629068   \n",
       "\n",
       "    ROC-AUC  \n",
       "0  0.958096  \n",
       "1  0.933328  \n",
       "2  2.476819  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "========================================\n",
      "===== Hasil Hyperparameter Tuning (XGBoost) =====\n",
      "Best Hyperparameter: {'subsample': 0.6, 'n_estimators': np.int64(500), 'max_depth': 2, 'learning_rate': np.float64(0.3), 'gamma': 5, 'colsample_bytree': 0.8}\n",
      "Best F1 Score : 0.8889708086767977\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.954167</td>\n",
       "      <td>0.962099</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.947201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.943333</td>\n",
       "      <td>0.963415</td>\n",
       "      <td>0.849462</td>\n",
       "      <td>0.902857</td>\n",
       "      <td>0.938393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Gap (%)</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>-0.131551</td>\n",
       "      <td>3.763441</td>\n",
       "      <td>2.021978</td>\n",
       "      <td>0.880798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  Dataset  Accuracy  Precision    Recall  F1-Score   ROC-AUC\n",
       "0  XGBoost    Train  0.954167   0.962099  0.887097  0.923077  0.947201\n",
       "1  XGBoost     Test  0.943333   0.963415  0.849462  0.902857  0.938393\n",
       "2  XGBoost  Gap (%)  1.083333  -0.131551  3.763441  2.021978  0.880798"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ Final Comparison ================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.911290</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.998299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.935432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Gap (%)</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>1.413793</td>\n",
       "      <td>13.709677</td>\n",
       "      <td>8.452381</td>\n",
       "      <td>6.286686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.963068</td>\n",
       "      <td>0.911290</td>\n",
       "      <td>0.936464</td>\n",
       "      <td>0.958096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.936667</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.827957</td>\n",
       "      <td>0.890173</td>\n",
       "      <td>0.933328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Gap (%)</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.056818</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>4.629068</td>\n",
       "      <td>2.476819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.954167</td>\n",
       "      <td>0.962099</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.947201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.943333</td>\n",
       "      <td>0.963415</td>\n",
       "      <td>0.849462</td>\n",
       "      <td>0.902857</td>\n",
       "      <td>0.938393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Gap (%)</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>-0.131551</td>\n",
       "      <td>3.763441</td>\n",
       "      <td>2.021978</td>\n",
       "      <td>0.880798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Dataset  Accuracy  Precision     Recall  F1-Score  \\\n",
       "0      Random Forest    Train  0.965000   0.974138   0.911290  0.941667   \n",
       "1      Random Forest     Test  0.920000   0.960000   0.774194  0.857143   \n",
       "2      Random Forest  Gap (%)  4.500000   1.413793  13.709677  8.452381   \n",
       "3  Gradient Boosting    Train  0.961667   0.963068   0.911290  0.936464   \n",
       "4  Gradient Boosting     Test  0.936667   0.962500   0.827957  0.890173   \n",
       "5  Gradient Boosting  Gap (%)  2.500000   0.056818   8.333333  4.629068   \n",
       "6            XGBoost    Train  0.954167   0.962099   0.887097  0.923077   \n",
       "7            XGBoost     Test  0.943333   0.963415   0.849462  0.902857   \n",
       "8            XGBoost  Gap (%)  1.083333  -0.131551   3.763441  2.021978   \n",
       "\n",
       "    ROC-AUC  \n",
       "0  0.998299  \n",
       "1  0.935432  \n",
       "2  6.286686  \n",
       "3  0.958096  \n",
       "4  0.933328  \n",
       "5  2.476819  \n",
       "6  0.947201  \n",
       "7  0.938393  \n",
       "8  0.880798  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# =========================================\n",
    "# Random Forest dengan RandomizedSearchCV\n",
    "# =========================================\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [2, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf_random = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=rf_param_dist,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ✅ gunakan X_train_transformed dan X_test_transformed\n",
    "rf_random.fit(X_train_transformed, y_train)\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(\"===== Hasil Hyperparameter Tuning (Random Forest) =====\")\n",
    "print(\"Best Hyperparameter:\", rf_random.best_params_)\n",
    "print(\"Best F1 Score :\", rf_random.best_score_)\n",
    "\n",
    "# Evaluasi Train vs Test\n",
    "best_rf = rf_random.best_estimator_\n",
    "df_rf_eval = evaluate_train_test(best_rf, X_train_transformed, y_train,\n",
    "                                 X_test_transformed, y_test,\n",
    "                                 model_name=\"Random Forest\")\n",
    "print(\"\\nResult Model evaluation Train vs Test:\\n\")\n",
    "display(df_rf_eval)\n",
    "\n",
    "# =========================================\n",
    "# 2. Gradient Boosting\n",
    "# =========================================\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb_param_dist = {\n",
    "    'n_estimators': np.arange(100, 501, 50),\n",
    "    'learning_rate': np.linspace(0.01, 0.3, 10),\n",
    "    'max_depth': [2, 3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "gb_random = RandomizedSearchCV(\n",
    "    estimator=gb,\n",
    "    param_distributions=gb_param_dist,\n",
    "    n_iter=30,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "gb_random.fit(X_train_transformed, y_train)\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(\"===== Hasil Hyperparameter Tuning (Gradient Boosting) =====\")\n",
    "print(\"Best Hyperparameter:\", gb_random.best_params_)\n",
    "print(\"Best F1 Score :\", gb_random.best_score_)\n",
    "\n",
    "best_gb = gb_random.best_estimator_\n",
    "df_gb_eval = evaluate_train_test(best_gb, X_train_transformed, y_train,\n",
    "                                 X_test_transformed, y_test,\n",
    "                                 model_name=\"Gradient Boosting\")\n",
    "display(df_gb_eval)\n",
    "\n",
    "# =========================================\n",
    "# 3. XGBoost\n",
    "# =========================================\n",
    "xgb = XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "\n",
    "\n",
    "xgb_param_dist = {\n",
    "    'n_estimators': np.arange(100, 501, 50),\n",
    "    'learning_rate': np.linspace(0.01, 0.3, 10),\n",
    "    'max_depth': [2, 3, 5, 7],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 1, 5]\n",
    "}\n",
    "\n",
    "xgb_random = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=xgb_param_dist,\n",
    "    n_iter=30,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb_random.fit(X_train_transformed, y_train)\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(\"===== Hasil Hyperparameter Tuning (XGBoost) =====\")\n",
    "print(\"Best Hyperparameter:\", xgb_random.best_params_)\n",
    "print(\"Best F1 Score :\", xgb_random.best_score_)\n",
    "\n",
    "best_xgb = xgb_random.best_estimator_\n",
    "df_xgb_eval = evaluate_train_test(best_xgb, X_train_transformed, y_train,\n",
    "                                  X_test_transformed, y_test,\n",
    "                                  model_name=\"XGBoost\")\n",
    "display(df_xgb_eval)\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# Gabungkan semua hasil evaluasi jadi 1 tabel\n",
    "# =========================================\n",
    "final_results = pd.concat([df_rf_eval, df_gb_eval, df_xgb_eval], ignore_index=True)\n",
    "print(\"\\n================ Final Comparison ================\")\n",
    "display(final_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1d8859dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Nama folder yang diinginkan\n",
    "# folder_path = 'file_exp'\n",
    "\n",
    "# # Cek apakah folder sudah ada, jika tidak, buat folder tersebut\n",
    "# if not os.path.exists(folder_path):\n",
    "#     os.path.makedirs(folder_path)\n",
    "#     print(f\"Folder '{folder_path}' berhasil dibuat.\")\n",
    "\n",
    "# # Buat path lengkap untuk file Excel\n",
    "# file_path = os.path.join(folder_path, 'final_result.xlsx')\n",
    "\n",
    "# # Asumsikan 'hasil_evaluasi' adalah DataFrame\n",
    "# final_results.to_excel(file_path, index=True)\n",
    "\n",
    "# print(f\"Hasil evaluasi telah berhasil disimpan ke: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cdd4bb",
   "metadata": {},
   "source": [
    "## XGBoost memberikan hasil yang lebih baik dan stabil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6e49bb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "========================================\n",
      "===== Hasil Hyperparameter Tuning  RandomizedSearchCV (XGBoost) =====\n",
      "Best Hyperparameter: {'subsample': 0.6, 'n_estimators': np.int64(500), 'max_depth': 2, 'learning_rate': np.float64(0.3), 'gamma': 5, 'colsample_bytree': 0.8}\n",
      "Best F1 Score : 0.8889708086767977\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.954167</td>\n",
       "      <td>0.962099</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.947201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.943333</td>\n",
       "      <td>0.963415</td>\n",
       "      <td>0.849462</td>\n",
       "      <td>0.902857</td>\n",
       "      <td>0.938393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Gap (%)</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>-0.131551</td>\n",
       "      <td>3.763441</td>\n",
       "      <td>2.021978</td>\n",
       "      <td>0.880798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  Dataset  Accuracy  Precision    Recall  F1-Score   ROC-AUC\n",
       "0  XGBoost    Train  0.954167   0.962099  0.887097  0.923077  0.947201\n",
       "1  XGBoost     Test  0.943333   0.963415  0.849462  0.902857  0.938393\n",
       "2  XGBoost  Gap (%)  1.083333  -0.131551  3.763441  2.021978  0.880798"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================================\n",
    "# 3. XGBoost\n",
    "# =========================================\n",
    "xgb = XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "\n",
    "\n",
    "xgb_param_dist = {\n",
    "    'n_estimators': np.arange(100, 501, 50),\n",
    "    'learning_rate': np.linspace(0.01, 0.3, 10),\n",
    "    'max_depth': [2, 3, 5, 7],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 1, 5]\n",
    "}\n",
    "\n",
    "xgb_random = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=xgb_param_dist,\n",
    "    n_iter=30,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb_random.fit(X_train_transformed, y_train)\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(\"===== Hasil Hyperparameter Tuning  RandomizedSearchCV (XGBoost) =====\")\n",
    "print(\"Best Hyperparameter:\", xgb_random.best_params_)\n",
    "print(\"Best F1 Score :\", xgb_random.best_score_)\n",
    "\n",
    "best_xgb = xgb_random.best_estimator_\n",
    "df_xgb_eval = evaluate_train_test(best_xgb, X_train_transformed, y_train,\n",
    "                                  X_test_transformed, y_test,\n",
    "                                  model_name=\"XGBoost\")\n",
    "display(df_xgb_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8867ed8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2700 candidates, totalling 13500 fits\n",
      "========================================\n",
      "===== Hasil Hyperparameter Tuning  GridSearchCV (XGBoost) =====\n",
      "Best Hyperparameter: {'colsample_bytree': 1.0, 'gamma': 5, 'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 300, 'subsample': 0.6}\n",
      "Best F1 Score : 0.9027462533795798\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost GridSearch</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.951667</td>\n",
       "      <td>0.961765</td>\n",
       "      <td>0.879032</td>\n",
       "      <td>0.918539</td>\n",
       "      <td>0.947426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost GridSearch</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.943333</td>\n",
       "      <td>0.963415</td>\n",
       "      <td>0.849462</td>\n",
       "      <td>0.902857</td>\n",
       "      <td>0.934990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost GridSearch</td>\n",
       "      <td>Gap (%)</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>-0.164993</td>\n",
       "      <td>2.956989</td>\n",
       "      <td>1.568218</td>\n",
       "      <td>1.243604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Dataset  Accuracy  Precision    Recall  F1-Score  \\\n",
       "0  XGBoost GridSearch    Train  0.951667   0.961765  0.879032  0.918539   \n",
       "1  XGBoost GridSearch     Test  0.943333   0.963415  0.849462  0.902857   \n",
       "2  XGBoost GridSearch  Gap (%)  0.833333  -0.164993  2.956989  1.568218   \n",
       "\n",
       "    ROC-AUC  \n",
       "0  0.947426  \n",
       "1  0.934990  \n",
       "2  1.243604  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================================\n",
    "# XGBoost - Grid Search\n",
    "# =========================================\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgb = XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    'max_depth': [2, 3, 5, 7],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 1, 5]\n",
    "}\n",
    "\n",
    "xgb_grid = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=xgb_param_grid,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb_grid.fit(X_train_transformed, y_train)\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(\"===== Hasil Hyperparameter Tuning  GridSearchCV (XGBoost) =====\")\n",
    "print(\"Best Hyperparameter:\", xgb_grid.best_params_)\n",
    "print(\"Best F1 Score :\", xgb_grid.best_score_)\n",
    "\n",
    "best_xgb_grid = xgb_grid.best_estimator_\n",
    "df_xgb_eval_grid = evaluate_train_test(best_xgb_grid, X_train_transformed, y_train,\n",
    "                                       X_test_transformed, y_test,\n",
    "                                       model_name=\"XGBoost GridSearch\")\n",
    "display(df_xgb_eval_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8532348e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 15:42:50,310] A new study created in memory with name: no-name-aee1085b-779b-445b-8beb-ff89f17782b5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea598af21f5c40f1a107fccdd93fee08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 15:42:50,702] Trial 0 finished with value: 0.8709016557204776 and parameters: {'n_estimators': 400, 'learning_rate': 0.023546803681402623, 'max_depth': 7, 'subsample': 0.9062491680327518, 'colsample_bytree': 0.6965969426999572, 'gamma': 1}. Best is trial 0 with value: 0.8709016557204776.\n",
      "[I 2025-09-13 15:42:51,048] Trial 1 finished with value: 0.864213352560046 and parameters: {'n_estimators': 300, 'learning_rate': 0.02971852615086878, 'max_depth': 9, 'subsample': 0.6552695918465258, 'colsample_bytree': 0.7219627481121719, 'gamma': 0}. Best is trial 0 with value: 0.8709016557204776.\n",
      "[I 2025-09-13 15:42:51,206] Trial 2 finished with value: 0.8307505444299732 and parameters: {'n_estimators': 350, 'learning_rate': 0.010138352826601726, 'max_depth': 8, 'subsample': 0.8699891421354946, 'colsample_bytree': 0.6246773365217992, 'gamma': 3}. Best is trial 0 with value: 0.8709016557204776.\n",
      "[I 2025-09-13 15:42:51,330] Trial 3 finished with value: 0.860400068277275 and parameters: {'n_estimators': 250, 'learning_rate': 0.03170582669572249, 'max_depth': 2, 'subsample': 0.8942064041700124, 'colsample_bytree': 0.959980247532245, 'gamma': 0}. Best is trial 0 with value: 0.8709016557204776.\n",
      "[I 2025-09-13 15:42:51,478] Trial 4 finished with value: 0.8632830812445109 and parameters: {'n_estimators': 450, 'learning_rate': 0.09356882632155936, 'max_depth': 2, 'subsample': 0.6661032113879297, 'colsample_bytree': 0.9521797002656546, 'gamma': 0}. Best is trial 0 with value: 0.8709016557204776.\n",
      "[I 2025-09-13 15:42:51,582] Trial 5 finished with value: 0.8343418084263154 and parameters: {'n_estimators': 100, 'learning_rate': 0.23959280678058373, 'max_depth': 8, 'subsample': 0.9210386376995763, 'colsample_bytree': 0.6572560559262702, 'gamma': 0}. Best is trial 0 with value: 0.8709016557204776.\n",
      "[I 2025-09-13 15:42:51,688] Trial 6 finished with value: 0.8619152094737583 and parameters: {'n_estimators': 100, 'learning_rate': 0.040804517220183335, 'max_depth': 6, 'subsample': 0.9335468202309554, 'colsample_bytree': 0.8670380514758191, 'gamma': 0}. Best is trial 0 with value: 0.8709016557204776.\n",
      "[I 2025-09-13 15:42:51,943] Trial 7 finished with value: 0.8514348289137154 and parameters: {'n_estimators': 350, 'learning_rate': 0.04394166533730414, 'max_depth': 7, 'subsample': 0.9688804159953327, 'colsample_bytree': 0.6516059637470786, 'gamma': 0}. Best is trial 0 with value: 0.8709016557204776.\n",
      "[I 2025-09-13 15:42:52,130] Trial 8 finished with value: 0.8872580726117111 and parameters: {'n_estimators': 400, 'learning_rate': 0.23124333277051765, 'max_depth': 2, 'subsample': 0.7583210917020611, 'colsample_bytree': 0.7031255832183001, 'gamma': 5}. Best is trial 8 with value: 0.8872580726117111.\n",
      "[I 2025-09-13 15:42:52,333] Trial 9 finished with value: 0.8459651926173912 and parameters: {'n_estimators': 400, 'learning_rate': 0.06157697679364802, 'max_depth': 4, 'subsample': 0.8666368602311947, 'colsample_bytree': 0.8135845988930887, 'gamma': 0}. Best is trial 8 with value: 0.8872580726117111.\n",
      "[I 2025-09-13 15:42:52,496] Trial 10 finished with value: 0.8747804738052427 and parameters: {'n_estimators': 500, 'learning_rate': 0.27984843003937465, 'max_depth': 4, 'subsample': 0.755210506850363, 'colsample_bytree': 0.7895576766973222, 'gamma': 5}. Best is trial 8 with value: 0.8872580726117111.\n",
      "[I 2025-09-13 15:42:52,677] Trial 11 finished with value: 0.8704293993728083 and parameters: {'n_estimators': 500, 'learning_rate': 0.26770458628979554, 'max_depth': 4, 'subsample': 0.7370821505076572, 'colsample_bytree': 0.7552749472626717, 'gamma': 5}. Best is trial 8 with value: 0.8872580726117111.\n",
      "[I 2025-09-13 15:42:52,824] Trial 12 finished with value: 0.8647007478642486 and parameters: {'n_estimators': 500, 'learning_rate': 0.14274954089305678, 'max_depth': 4, 'subsample': 0.7957509903463803, 'colsample_bytree': 0.8185766699531182, 'gamma': 5}. Best is trial 8 with value: 0.8872580726117111.\n",
      "[I 2025-09-13 15:42:52,974] Trial 13 finished with value: 0.8864896470501549 and parameters: {'n_estimators': 450, 'learning_rate': 0.17842173379221238, 'max_depth': 3, 'subsample': 0.7548239982699209, 'colsample_bytree': 0.8847172528595841, 'gamma': 4}. Best is trial 8 with value: 0.8872580726117111.\n",
      "[I 2025-09-13 15:42:53,126] Trial 14 finished with value: 0.8921133840661888 and parameters: {'n_estimators': 200, 'learning_rate': 0.14458024455634175, 'max_depth': 2, 'subsample': 0.7107557226767356, 'colsample_bytree': 0.893871435110745, 'gamma': 4}. Best is trial 14 with value: 0.8921133840661888.\n",
      "[I 2025-09-13 15:42:53,253] Trial 15 finished with value: 0.8898545881581967 and parameters: {'n_estimators': 200, 'learning_rate': 0.11054030158343015, 'max_depth': 2, 'subsample': 0.6189416773195148, 'colsample_bytree': 0.9018418360833973, 'gamma': 3}. Best is trial 14 with value: 0.8921133840661888.\n",
      "[I 2025-09-13 15:42:53,369] Trial 16 finished with value: 0.8678467823916682 and parameters: {'n_estimators': 200, 'learning_rate': 0.10511713825867061, 'max_depth': 5, 'subsample': 0.6082844994839277, 'colsample_bytree': 0.9995045797826572, 'gamma': 3}. Best is trial 14 with value: 0.8921133840661888.\n",
      "[I 2025-09-13 15:42:53,484] Trial 17 finished with value: 0.8865165292071676 and parameters: {'n_estimators': 200, 'learning_rate': 0.07639193760652974, 'max_depth': 3, 'subsample': 0.684567383757689, 'colsample_bytree': 0.8887383359202939, 'gamma': 2}. Best is trial 14 with value: 0.8921133840661888.\n",
      "[I 2025-09-13 15:42:53,588] Trial 18 finished with value: 0.8684822604692906 and parameters: {'n_estimators': 150, 'learning_rate': 0.13205865799697958, 'max_depth': 10, 'subsample': 0.6051988830786084, 'colsample_bytree': 0.921801898992646, 'gamma': 4}. Best is trial 14 with value: 0.8921133840661888.\n",
      "[I 2025-09-13 15:42:53,713] Trial 19 finished with value: 0.8866934709645706 and parameters: {'n_estimators': 250, 'learning_rate': 0.16183243199909855, 'max_depth': 3, 'subsample': 0.7049521368861581, 'colsample_bytree': 0.8522441825232172, 'gamma': 2}. Best is trial 14 with value: 0.8921133840661888.\n",
      "[I 2025-09-13 15:42:53,870] Trial 20 finished with value: 0.8607866020120676 and parameters: {'n_estimators': 150, 'learning_rate': 0.06669652616342193, 'max_depth': 5, 'subsample': 0.6331768177237278, 'colsample_bytree': 0.9276228159466752, 'gamma': 4}. Best is trial 14 with value: 0.8921133840661888.\n",
      "[I 2025-09-13 15:42:53,982] Trial 21 finished with value: 0.8879368399730552 and parameters: {'n_estimators': 250, 'learning_rate': 0.18337565604268874, 'max_depth': 2, 'subsample': 0.7163504454593757, 'colsample_bytree': 0.7537589891741968, 'gamma': 4}. Best is trial 14 with value: 0.8921133840661888.\n",
      "[I 2025-09-13 15:42:54,088] Trial 22 finished with value: 0.8924987587573648 and parameters: {'n_estimators': 250, 'learning_rate': 0.10218524956947234, 'max_depth': 2, 'subsample': 0.7081614078175367, 'colsample_bytree': 0.7699315278954997, 'gamma': 3}. Best is trial 22 with value: 0.8924987587573648.\n",
      "[I 2025-09-13 15:42:54,200] Trial 23 finished with value: 0.8787713966598425 and parameters: {'n_estimators': 200, 'learning_rate': 0.09720977886857853, 'max_depth': 3, 'subsample': 0.8046942192343942, 'colsample_bytree': 0.8445566281238623, 'gamma': 3}. Best is trial 22 with value: 0.8924987587573648.\n",
      "[I 2025-09-13 15:42:54,325] Trial 24 finished with value: 0.8940074320455451 and parameters: {'n_estimators': 300, 'learning_rate': 0.12538944078318592, 'max_depth': 2, 'subsample': 0.6427560726775481, 'colsample_bytree': 0.777174377724389, 'gamma': 2}. Best is trial 24 with value: 0.8940074320455451.\n",
      "[I 2025-09-13 15:42:54,461] Trial 25 finished with value: 0.8826111453558262 and parameters: {'n_estimators': 300, 'learning_rate': 0.07753266170600749, 'max_depth': 3, 'subsample': 0.686068779801139, 'colsample_bytree': 0.7719011106740519, 'gamma': 2}. Best is trial 24 with value: 0.8940074320455451.\n",
      "[I 2025-09-13 15:42:54,673] Trial 26 finished with value: 0.8781093220727187 and parameters: {'n_estimators': 300, 'learning_rate': 0.13256654368234635, 'max_depth': 5, 'subsample': 0.8094331120658578, 'colsample_bytree': 0.8217349888517468, 'gamma': 1}. Best is trial 24 with value: 0.8940074320455451.\n",
      "[I 2025-09-13 15:42:54,792] Trial 27 finished with value: 0.889982993588523 and parameters: {'n_estimators': 250, 'learning_rate': 0.05211322762426955, 'max_depth': 2, 'subsample': 0.6480136405920961, 'colsample_bytree': 0.7429144463183631, 'gamma': 1}. Best is trial 24 with value: 0.8940074320455451.\n",
      "[I 2025-09-13 15:42:54,895] Trial 28 finished with value: 0.885045139403619 and parameters: {'n_estimators': 150, 'learning_rate': 0.19545190349847621, 'max_depth': 3, 'subsample': 0.7234549260839483, 'colsample_bytree': 0.7901483107503107, 'gamma': 2}. Best is trial 24 with value: 0.8940074320455451.\n",
      "[I 2025-09-13 15:42:55,062] Trial 29 finished with value: 0.8346978557504873 and parameters: {'n_estimators': 350, 'learning_rate': 0.012505858518016546, 'max_depth': 4, 'subsample': 0.6829640985204823, 'colsample_bytree': 0.6814331837842982, 'gamma': 3}. Best is trial 24 with value: 0.8940074320455451.\n",
      "========================================\n",
      "===== Hasil Hyperparameter Tuning  Bayesian Optimization (XGBoost) =====\n",
      "Best Hyperparameter: {'n_estimators': 300, 'learning_rate': 0.12538944078318592, 'max_depth': 2, 'subsample': 0.6427560726775481, 'colsample_bytree': 0.777174377724389, 'gamma': 2}\n",
      "Best F1 Score : 0.8940074320455451\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Bayesian</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.962644</td>\n",
       "      <td>0.900538</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.957642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost Bayesian</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.817204</td>\n",
       "      <td>0.878613</td>\n",
       "      <td>0.929770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost Bayesian</td>\n",
       "      <td>Gap (%)</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>1.264368</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>5.194284</td>\n",
       "      <td>2.787193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model  Dataset  Accuracy  Precision    Recall  F1-Score  \\\n",
       "0  XGBoost Bayesian    Train  0.958333   0.962644  0.900538  0.930556   \n",
       "1  XGBoost Bayesian     Test  0.930000   0.950000  0.817204  0.878613   \n",
       "2  XGBoost Bayesian  Gap (%)  2.833333   1.264368  8.333333  5.194284   \n",
       "\n",
       "    ROC-AUC  \n",
       "0  0.957642  \n",
       "1  0.929770  \n",
       "2  2.787193  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================================\n",
    "# XGBoost - Bayesian Optimization dengan Optuna\n",
    "# =========================================\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500, step=50),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'gamma': trial.suggest_int('gamma', 0, 5),\n",
    "        'random_state': 42,\n",
    "        'eval_metric': 'logloss',\n",
    "        'use_label_encoder': False\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**params)\n",
    "    scores = cross_val_score(model, X_train_transformed, y_train, cv=5, scoring='f1', n_jobs=-1)\n",
    "    return scores.mean()\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30, show_progress_bar=True)\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(\"===== Hasil Hyperparameter Tuning  Bayesian Optimization (XGBoost) =====\")\n",
    "print(\"Best Hyperparameter:\", study.best_trial.params)\n",
    "print(\"Best F1 Score :\", study.best_value)\n",
    "\n",
    "best_xgb_bayes = XGBClassifier(**study.best_trial.params)\n",
    "best_xgb_bayes.fit(X_train_transformed, y_train)\n",
    "\n",
    "df_xgb_eval_bayes = evaluate_train_test(best_xgb_bayes, X_train_transformed, y_train,\n",
    "                                        X_test_transformed, y_test,\n",
    "                                        model_name=\"XGBoost Bayesian\")\n",
    "display(df_xgb_eval_bayes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d348754",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "acd97179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model terbaik berhasil disimpan di file 'best_xgboost_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "model_filename = 'best_xgboost_model.pkl'\n",
    "joblib.dump(best_xgb, model_filename)\n",
    "print(f\"\\nModel terbaik berhasil disimpan di file '{model_filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "475386ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model terbaik berhasil disimpan di file \n"
     ]
    }
   ],
   "source": [
    "joblib.dump(best_xgb, 'best_xgboost_model.joblib')\n",
    "print(f\"\\nModel terbaik berhasil disimpan di file \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6856963e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model berhasil dimuat.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    best_xgboost_model = joblib.load('best_xgboost_model.pkl')\n",
    "    print(\"Model berhasil dimuat.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"File 'best_xgboost_model.pkl' tidak ditemukan. Pastikan path sudah benar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "676cf363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediksi berhasil dilakukan.\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_xgboost_model.predict(X_test_transformed)\n",
    "print(\"Prediksi berhasil dilakukan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cdab4d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[204   3]\n",
      " [ 14  79]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Hitung confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Tampilkan visualisasi confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_xgboost_model.classes_)\n",
    "disp.plot()\n",
    "\n",
    "# Tambahkan judul dan tampilkan plot\n",
    "plt.title('Confusion Matrix for Best XGBoost Model')\n",
    "plt.show()\n",
    "\n",
    "# Jika ingin melihat angkanya saja\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd713e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latihan_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
